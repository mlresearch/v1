<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Gaussian Processes in Practice</title>
    <description>Gaussian Processes in Practice, Bletchley Park, UK</description>
    <link>http://proceedings.mlr.press/v1/</link>
    <atom:link href="http://proceedings.mlr.press/v1/feed.xml" rel="self" type="application/rss+xml"/>
    <pubDate>Thu, 23 Feb 2017 22:00:15 +0000</pubDate>
    <lastBuildDate>Thu, 23 Feb 2017 22:00:15 +0000</lastBuildDate>
    <generator>Jekyll v3.2.1</generator>
    
      <item>
        <title>Sparse Log Gaussian Processes via MCMC for Spatial Epidemiology</title>
        <description>Log Gaussian processes are an attractive manner to construct intensity surfaces for the purposes of spatial epidemiology. The intensity surfaces are naturally smoothed by placing a Gaussian process (GP) prior over the relative log Poisson rate, and the spatial correlations between areas can be included in an explicit and natural way into the model via a correlation function. The drawback with using a Gaussian process is the computational burden of the covariance matrix calculations.  To overcome the computational limitations a number of approximations for Gaussian process have been suggested in the literature. In this work a fully independent training conditional sparse approximation is used to speed up the computations. The posterior inference is conducted using Markov chain Monte Carlo simulations and the sampling of the latent values is sped up by a transformation taking into account their posterior covariance. The sparse approximation is compared to a full GP with two sets of mortality data.</description>
        <pubDate>Sun, 11 Mar 2007 00:00:00 +0000</pubDate>
        <link>http://proceedings.mlr.press/v1/vanhatalo07a.html</link>
        <guid isPermaLink="true">http://proceedings.mlr.press/v1/vanhatalo07a.html</guid>
        
        
      </item>
    
      <item>
        <title>Multi-class Semi-supervised Learning with the e-truncated Multinomial Probit Gaussian Process</title>
        <description>Recently, the null category noise model has been proposed as a simple and elegant solution to the problem of incorporating unlabeled data into a Gaussian process (GP) classification model. In this paper, we show how this binary likelihood model can be generalised to the multi-class setting through the use of the multinomial probit GP classifier. We present a Gibbs sampling scheme for sampling the GP parameters and also derive a more efficient variational updating scheme. We find that the performance improvement is roughly consistent with that observed in binary classification and that there is no significant difference in classification performance between the Gibbs sampling and variational schemes.</description>
        <pubDate>Sun, 11 Mar 2007 00:00:00 +0000</pubDate>
        <link>http://proceedings.mlr.press/v1/rogers07a.html</link>
        <guid isPermaLink="true">http://proceedings.mlr.press/v1/rogers07a.html</guid>
        
        
      </item>
    
      <item>
        <title>Salient Point and Scale Detection by Minimum Likelihood</title>
        <description>We propose a novel approach for detection of salient image points and estimation of their intrinsic scales based on the fractional Brownian image model.  Under this model images are realisations of a Gaussian random process on the plane. We define salient points as points that have a locally unique image structure. Such points are usually sparsely distributed in images and carry important information about the image content. Locality is defined in terms of the measurement scale of the filters used to describe the image structure.  Here we use partial derivatives of the image function defined using linear scale space theory. We propose to detect salient points and their intrinsic scale by detecting points in scale-space that locally minimise the likelihood under the model.</description>
        <pubDate>Sun, 11 Mar 2007 00:00:00 +0000</pubDate>
        <link>http://proceedings.mlr.press/v1/pedersen07a.html</link>
        <guid isPermaLink="true">http://proceedings.mlr.press/v1/pedersen07a.html</guid>
        
        
      </item>
    
      <item>
        <title>Learning RoboCup-Keepaway with Kernels</title>
        <description>We apply kernel-based methods to solve the difficult reinforcement learning problem of 3vs2 keepaway in RoboCup simulated soccer. Key challenges in keepaway are the highdimensionality of the state space (rendering conventional discretization-based function approximation like tilecoding infeasible), the stochasticity due to noise and multiple learning agents needing to cooperate (meaning that the exact dynamics of the environment are unknown) and real-time learning (meaning that an efficient online implementation is required).  We employ the general framework of approximate policy iteration with least-squares-based policy evaluation. As underlying function approximator we consider the family of regularization networks with subset of regressors approximation. The core of our proposed solution is an efficient recursive implementation with automatic supervised selection of relevant basis functions. Simulation results indicate that the behavior learned through our approach clearly outperforms the best results obtained with tilecoding by Stone et al. (2005).</description>
        <pubDate>Sun, 11 Mar 2007 00:00:00 +0000</pubDate>
        <link>http://proceedings.mlr.press/v1/jung07a.html</link>
        <guid isPermaLink="true">http://proceedings.mlr.press/v1/jung07a.html</guid>
        
        
      </item>
    
      <item>
        <title>Gaussian Process Approximations of Stochastic Differential Equations</title>
        <description>Stochastic differential equations arise naturally in a range of contexts, from financial to environmental modeling. Current solution methods are limited in their representation of the posterior process in the presence of data. In this work, we present a novel Gaussian process approximation to the posterior measure \emphover paths for a general class of stochastic differential equations in the presence of observations. The method is applied to two simple problems: the Ornstein-Uhlenbeck process, of which the exact solution is known and can be compared to, and the double-well system, for which standard approaches such as the ensemble Kalman smoother fail to provide a satisfactory result. Experiments show that our variational approximation is viable and that the results are very promising as the variational approximate solution outperforms standard Gaussian process regression for non-Gaussian Markov processes.</description>
        <pubDate>Sun, 11 Mar 2007 00:00:00 +0000</pubDate>
        <link>http://proceedings.mlr.press/v1/archambeau07a.html</link>
        <guid isPermaLink="true">http://proceedings.mlr.press/v1/archambeau07a.html</guid>
        
        
      </item>
    
  </channel>
</rss>
