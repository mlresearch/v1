 <head> 
  <!--#include virtual="/css-scroll.txt"-->
<style>
. {font-family:verdana,helvetica,sans-serif}
a {text-decoration:none;color:#3030a0}
</style>
</head> 
 <body>
 <div id="content">
<h2>Learning RoboCup-Keepaway with Kernels</h2>
<p><i><b>Tobias Jung, Daniel Polani</b></i>; 
JMLR W&P 1:33-57, 2007.</p>
<h3>Abstract</h3>

We apply kernel-based methods to solve the difficult reinforcement
learning problem of 3vs2 keepaway in RoboCup simulated soccer. Key
challenges in keepaway are the highdimensionality of the state space
(rendering conventional discretization-based function approximation
like tilecoding infeasible), the stochasticity due to noise and
multiple learning agents needing to cooperate (meaning that the exact
dynamics of the environment are unknown) and real-time learning
(meaning that an efficient online implementation is required).  We
employ the general framework of approximate policy iteration with
least-squares-based policy evaluation. As underlying function
approximator we consider the family of regularization networks with
subset of regressors approximation. The core of our proposed solution
is an efficient recursive implementation with automatic supervised
selection of relevant basis functions. Simulation results indicate
that the behavior learned through our approach clearly outperforms the
best results obtained with tilecoding by Stone et al. (2005).

</div>
 <!--#include virtual="/nav-bar.txt"--> 
</body>